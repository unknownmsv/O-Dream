# main.py
import os
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import requests
from typing import Dict, List, Any, Literal # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Literal Ø¨Ø±Ø§ÛŒ ØªØ¹Ø±ÛŒÙ Ù†ÙˆØ¹ verbosity

# ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† ØªØ§Ø¨Ø¹ create_img Ø§Ø² ÙØ§ÛŒÙ„ image.py
# Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ ÙØ§ÛŒÙ„ image.py Ø¯Ø± Ú©Ù†Ø§Ø± main.py Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯ Ùˆ Ù…Ø³ÛŒØ± 'function.image' ØµØ­ÛŒØ­ Ø¨Ø§Ø´Ø¯.
from function.image import create_img 

# --- 1. Load Environment Variables ---
# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ .env
load_dotenv()

# --- 2. Configuration ---
# Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯ API Gemini Ø§Ø² Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")
# Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯ API OpenAI Ø§Ø² Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not GEMINI_API_KEY:
    raise ValueError("GOOGLE_API_KEY Ø¯Ø± Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¢Ù† Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ .env ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.")
# Ù‡Ø´Ø¯Ø§Ø± Ø¯Ø± Ù…ÙˆØ±Ø¯ Ú©Ù„ÛŒØ¯ OpenAI Ø§Ú¯Ø± ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
if not OPENAI_API_KEY:
    print("Ù‡Ø´Ø¯Ø§Ø±: OPENAI_API_KEY Ø¯Ø± Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù‚Ø§Ø¨Ù„ÛŒØª ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ø§Ø± Ù†Ú©Ù†Ø¯.")


# Ø¢Ø¯Ø±Ø³ Ù¾Ø§ÛŒÙ‡ API Ø¨Ø±Ø§ÛŒ Gemini
GEMINI_API_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/models"

# --- 3. Initialize FastAPI App ---
app = FastAPI(
    title="Oâ‚‚Dream AI Gateway (Requests Version)",
    description="ÛŒÚ© Ø¯Ø±ÙˆØ§Ø²Ù‡ API Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Gemini Ø¨Ø±Ø§ÛŒ Ú†Øª Ùˆ ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯ØŒ Ùˆ DALLÂ·E 3 Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ±.",
    version="0.1.0"
)

# --- 4. Model Names ---
CHAT_MODEL_NAME = 'gemini-1.5-flash-latest'
# Ù†Ø§Ù… Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ. 'gemini-1.5-pro-latest' Ù†Ø§Ù… Ø¹Ù…ÙˆÙ…ÛŒ Ùˆ Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.
# 'gemini-2.5-pro' Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± ÛŒÚ© Ù†Ø§Ù… Ù…Ø¯Ù„ Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø± API Gemini Ù†ÛŒØ³Øª.
CODE_MODEL_NAME = 'gemini-1.5-pro-latest' 

# --- 5. In-memory Chat History Storage ---
# Ø§ÛŒÙ† Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± session_id Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
# ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¨Ù‡ ÙØ±Ù…Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Gemini API (Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ role Ùˆ parts) Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
chat_sessions: Dict[str, List[Dict[str, Any]]] = {}

# --- Pydantic Models for Request Bodies ---
class ChatRequest(BaseModel):
    session_id: str # ÛŒÚ© Ø´Ù†Ø§Ø³Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¬Ù„Ø³Ù‡ Ú†Øª Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ ØªØ§Ø±ÛŒØ®Ú†Ù‡
    message: str    # Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±

class CodeRequest(BaseModel):
    prompt: str     # Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø§Ø² Ú©Ø§Ø±Ø¨Ø±
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙÛŒÙ„Ø¯ verbosity Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø¬Ø§Ø² 'low', 'medium', 'high'
    verbosity: Literal["low", "medium", "high"] = "medium" 

class ChatResponse(BaseModel):
    session_id: str
    response: str
    history: List[Dict[str, Any]] # ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯ÛŒÙ†Ú¯ ÛŒØ§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯

class CodeResponse(BaseModel):
    prompt: str
    code_output: str
    verbosity: str # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† verbosity Ø¨Ù‡ Ù¾Ø§Ø³Ø® Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ

# --- Helper Function to Call Gemini API ---
async def call_gemini_api(model_name: str, payload: Dict[str, Any]) -> str:
    """
    ÛŒÚ© Ø¯Ø±Ø®ÙˆØ§Ø³Øª POST Ø¨Ù‡ Gemini API Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    url = f"{GEMINI_API_BASE_URL}/{model_name}:generateContent?key={GEMINI_API_KEY}" # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GEMINI_API_KEY
    headers = {"Content-Type": "application/json"}

    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status() # Ø§Ú¯Ø± Ú©Ø¯ ÙˆØ¶Ø¹ÛŒØª HTTP Ø®Ø·Ø§ Ø¨Ø§Ø´Ø¯ØŒ ÛŒÚ© Ø§Ø³ØªØ«Ù†Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯

        json_response = response.json()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†
        if 'candidates' in json_response and len(json_response['candidates']) > 0 and \
           'content' in json_response['candidates'][0] and \
           'parts' in json_response['candidates'][0]['content'] and \
           len(json_response['candidates'][0]['content']['parts']) > 0 and \
           'text' in json_response['candidates'][0]['content']['parts'][0]:
            return json_response['candidates'][0]['content']['parts'][0]['text']
        else:
            # Ø§Ú¯Ø± Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ Ù†Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ø³Ø§Ø®ØªØ§Ø± ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¨Ø§Ø´Ø¯
            print(f"Ù¾Ø§Ø³Ø® ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø§Ø² Gemini API: {json_response}")
            return "Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ Ø§Ø² Ù…Ø¯Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯."

    except requests.exceptions.RequestException as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Gemini API: {e}")
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API: {e}")
    except Exception as e:
        print(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø³Ø±ÙˆØ±: {e}")

# --- Translation Functions ---
async def translate_prompt_if_needed(prompt: str) -> str:
    """
    Ù¾Ø±Ø§Ù…Ù¾Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¯Ø± ØµÙˆØ±Øª ØºÛŒØ±Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨ÙˆØ¯Ù†ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    # ÛŒÚ© ØªØ³Øª Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¨Ø¨ÛŒÙ†ÛŒÙ… Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒÙ‡ ÛŒØ§ Ù†Ù‡ (Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ASCII)
    if not prompt.isascii():  
        print(f"[ğŸŒ] Ø¯Ø± Ø­Ø§Ù„ ØªØ±Ø¬Ù…Ù‡ Ù¾Ø±Ø§Ù…Ù¾Øª: '{prompt}'")
        translation = await translate_with_gemini(prompt) 
        print(f"[ğŸŒ] Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ±Ø¬Ù…Ù‡ Ø´Ø¯Ù‡: '{translation}'")
        return translation
    return prompt

async def translate_with_gemini(prompt: str) -> str:
    """
    Ù¾Ø±Ø§Ù…Ù¾Øª ÙØ§Ø±Ø³ÛŒ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Gemini Flash Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    translation_prompt = (
        f"Translate the following text to English. Respond only with the translation, no extra explanations or greetings:\n{prompt}"
    )
    payload = {
        "contents": [{"role": "user", "parts": [{"text": translation_prompt}]}],
        "generationConfig": {"responseMimeType": "text/plain"},
    }
    # Ø§Ø² Ù…Ø¯Ù„ ÙÙ„Ø´ Ø¨Ø±Ø§ÛŒ ØªØ±Ø¬Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    return await call_gemini_api(CHAT_MODEL_NAME, payload) 

# --- Dynamic System Instruction for Code Model based on Verbosity ---
def get_code_system_instruction(verbosity: str) -> str:
    """
    Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø·Ø­ verbosityØŒ system instruction Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    base_instruction = (
        "Ø´Ù…Ø§ ÛŒÚ© Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù† Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯ ØªÙ…ÛŒØ² Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡â€ŒØ§ÛŒØ¯. "
        "ØªÙ†Ù‡Ø§ Ù…Ø³Ø¦ÙˆÙ„ÛŒØª Ø´Ù…Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø§Ø³Øª. "
        "Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· Ø´Ø§Ù…Ù„ Ú©Ø¯ Ø¨Ø§Ø´Ø¯ Ùˆ Ø§Ø² ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ù„ÛŒ ÛŒØ§ Ù…Ú©Ø§Ù„Ù…Ù‡â€ŒØ§ÛŒ Ù¾Ø±Ù‡ÛŒØ² Ø´ÙˆØ¯. "
        "Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØºÛŒØ± Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø¯Ø§Ø´ØªØŒ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ ÙÙ‚Ø· Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯ Ø±Ø§ Ù…ÛŒâ€ŒÙ¾Ø°ÛŒØ±ÛŒØ¯. "
        "Ú©Ø¯ ØªÙˆÙ„ÛŒØ¯ÛŒ Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ø´ÛŒÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ù…Ø¯Ø±Ù† (Ù…Ø§Ù†Ù†Ø¯ ØªØ§Ø¨Ø¹â€ŒÙ†ÙˆÛŒØ³ÛŒØŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±) Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯. "
        "Ù‡Ù…ÛŒØ´Ù‡ ÙØ±Ø¶ Ú©Ù†ÛŒØ¯ Ú©Ø§Ø±Ø¨Ø± Ø§Ø² Ø´Ù…Ø§ Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ø§Ø±Ø¯ Ú©Ø¯ÛŒ ÙˆØ§Ù‚Ø¹ÛŒØŒ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†Ø¯."
    )

    if verbosity == "high":
        return (
            base_instruction + " Ú©Ø¯ Ø±Ø§ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„ ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯ØŒ Ù‡Ù… Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ù…ØªÙ† Ù‚Ø¨Ù„ ÛŒØ§ Ø¨Ø¹Ø¯ Ø§Ø² Ú©Ø¯ Ùˆ Ù‡Ù… Ø¨Ø§ Ú©Ø§Ù…Ù†Øªâ€ŒÙ‡Ø§ÛŒ ÙØ±Ø§ÙˆØ§Ù† Ø¯Ø± Ø¯Ø§Ø®Ù„ Ú©Ø¯. "
            "Ù‡Ø¯Ù Ø´Ù…Ø§ Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø¨ØªÙˆØ§Ù†Ø¯ Ù‡Ø± Ø®Ø· Ú©Ø¯ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ Ø¯Ø±Ú© Ú©Ù†Ø¯."
        )
    elif verbosity == "medium":
        return (
            base_instruction + " ØªÙˆØ¶ÛŒØ­Ø§Øª Ù…Ø®ØªØµØ±ÛŒ Ù‚Ø¨Ù„ ÛŒØ§ Ø¨Ø¹Ø¯ Ø§Ø² Ú©Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ùˆ Ø§Ø² Ú©Ø§Ù…Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ø¯Ø§Ø®Ù„ Ú©Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯. "
            "Ù‡Ø¯Ù Ø´Ù…Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ú©Ø¯ÛŒ Ø®ÙˆØ§Ù†Ø§ Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ú© Ù…Ù†Ø·Ù‚ Ø§ØµÙ„ÛŒ Ø§Ø³Øª."
        )
    elif verbosity == "low":
        return (
            base_instruction + " Ù‡ÛŒÚ† ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ù‚Ø¨Ù„ ÛŒØ§ Ø¨Ø¹Ø¯ Ø§Ø² Ú©Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø¯Ù‡ÛŒØ¯ Ùˆ Ù‡ÛŒÚ† Ú©Ø§Ù…Ù†ØªÛŒ Ø¯Ø± Ø¯Ø§Ø®Ù„ Ú©Ø¯ Ù‚Ø±Ø§Ø± Ù†Ø¯Ù‡ÛŒØ¯. "
            "Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ ØµØ±ÙØ§Ù‹ Ø´Ø§Ù…Ù„ Ú©Ø¯ Ø®Ø§Ù… Ø¨Ø§Ø´Ø¯."
        )
    else: # Default to medium if an invalid verbosity is provided
        return get_code_system_instruction("medium")

# --- System Instruction for Chat Model ---
chat_system_instruction_text = (
    "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ú†Øª Ùˆ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡â€ŒØ§ÛŒØ¯. "
    "ÙˆØ¸ÛŒÙÙ‡ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ØŒ Ù…ÙÛŒØ¯ Ùˆ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø³Øª. "
    "Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø§Ø² Ø´Ù…Ø§ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ú©Ø±Ø¯ØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ù‡ Ø§Ùˆ Ø¨Ú¯ÙˆÛŒÛŒØ¯ Ú©Ù‡ Ø´Ù…Ø§ Ù…Ø¯Ù„ÛŒ Ù†ÛŒØ³ØªÛŒØ¯ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯Ù‡Ø§ÛŒ ØªÙ…ÛŒØ² Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§Ø´ÛŒØ¯ "
    "Ùˆ Ø§Ùˆ Ø±Ø§ Ø¨Ù‡ Ø¨Ø®Ø´ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ (Ù…Ø«Ù„Ø§Ù‹ Ø¨Ø§ Ú¯ÙØªÙ† 'code: [Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø¯ Ø´Ù…Ø§] [verbosity: low/medium/high]') Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯. "
    "Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø§Ø² Ø´Ù…Ø§ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø³Ø§Ø®Øª ØªØµÙˆÛŒØ± Ú©Ø±Ø¯ØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ù‡ Ø§Ùˆ Ø¨Ú¯ÙˆÛŒÛŒØ¯ Ú©Ù‡ Ø´Ù…Ø§ Ù…Ø¯Ù„ÛŒ Ù†ÛŒØ³ØªÛŒØ¯ Ú©Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ ØªØµØ§ÙˆÛŒØ± Ø±Ø§ Ø¨Ø³Ø§Ø²ÛŒØ¯ "
    "Ùˆ Ø§Ùˆ Ø±Ø§ Ø¨Ù‡ Ø¨Ø®Ø´ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± (Ù…Ø«Ù„Ø§Ù‹ Ø¨Ø§ Ú¯ÙØªÙ† 'img: [ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙˆÛŒØ± Ø´Ù…Ø§]') Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯."
)

# --- 6. Chat Endpoint (/chat/gen) ---
@app.post("/chat/gen", response_model=ChatResponse)
async def generate_chat_response(request: ChatRequest):
    """
    Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù… Ø§Ø² Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø¢Ù† Ø¨Ù‡ Ù…Ø¯Ù„ Gemini 1.5 Flash Ø¨Ø±Ø§ÛŒ Ú†Øª Ø¹Ø§Ø¯ÛŒ.
    Ø§Ú¯Ø± Ù¾ÛŒØ§Ù… Ø¨Ø§ 'code:' ÛŒØ§ 'img:' Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯ØŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø±Ø§ Ø¨Ù‡ Ù…Ø¯Ù„ Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    session_id = request.session_id
    user_message = request.message

    # --- Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± ---
    if user_message.lower().startswith("img:"):
        original_image_prompt = user_message[len("img:"):].strip()
        print(f"[ğŸ–¼ï¸] Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø³Ø§Ø®Øª ØªØµÙˆÛŒØ±: '{original_image_prompt}' Ø¨Ø±Ø§ÛŒ session_id: {session_id}")

        if not OPENAI_API_KEY:
            return ChatResponse(
                session_id=session_id,
                response="âŒ Ù…ØªØ§Ø³ÙÙ…ØŒ Ú©Ù„ÛŒØ¯ API Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± (OpenAI) ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¢Ù† Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ .env Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯.",
                history=chat_sessions.get(session_id, [])
            )

        try:
            # ØªØ±Ø¬Ù…Ù‡ Ù¾Ø±Ø§Ù…Ù¾Øª Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ DALL-E
            translated_image_prompt = await translate_prompt_if_needed(original_image_prompt)
            
            # Ø§Ø±Ø³Ø§Ù„ Ú©Ù„ÛŒØ¯ API Ø¨Ù‡ ØªØ§Ø¨Ø¹ create_img
            image_url = await create_img(translated_image_prompt, openai_api_key=OPENAI_API_KEY) 
            return ChatResponse(
                session_id=session_id,
                response=f"ğŸ”— ØªØµÙˆÛŒØ± Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡:\n{image_url}",
                history=chat_sessions.get(session_id, [])
            )
        except Exception as e:
            return ChatResponse(
                session_id=session_id,
                response=f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ±: {e}",
                history=chat_sessions.get(session_id, [])
            )

    # --- Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ ---
    elif user_message.lower().startswith("code:"): # Ø§Ø² elif Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ ØªØ§ ÙÙ‚Ø· ÛŒÚ©ÛŒ Ø§Ø² Ø´Ø±Ø·â€ŒÙ‡Ø§ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ø±Ø§Ù…Ù¾Øª Ùˆ verbosity Ø§Ø² Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        parts = user_message[len("code:"):].strip().split("verbosity:")
        code_prompt = parts[0].strip()
        verbosity_level = "medium" # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        if len(parts) > 1:
            # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ verbosity ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª
            requested_verbosity = parts[1].strip().lower()
            if requested_verbosity in ["low", "medium", "high"]:
                verbosity_level = requested_verbosity
            else:
                # Ø§Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯ØŒ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø§Ø·Ù„Ø§Ø¹ Ø¯Ù‡ÛŒØ¯ Ùˆ Ø§Ø² Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
                return ChatResponse(
                    session_id=session_id,
                    response=f"âš ï¸ Ø³Ø·Ø­ verbosity Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª ('{requested_verbosity}'). Ø§Ø² 'medium' Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø¬Ø§Ø²: low, medium, high.",
                    history=chat_sessions.get(session_id, [])
                )

        print(f"[ğŸ’»] Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø¯ Ø§Ø² Ú†Øª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: '{code_prompt}' Ø¨Ø§ verbosity: {verbosity_level} Ø¨Ø±Ø§ÛŒ session_id: {session_id}")

        try:
            # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ generate_code_response Ø¨Ø§ verbosity_level
            code_response_obj = await generate_code_response(CodeRequest(prompt=code_prompt, verbosity=verbosity_level))
            
            # ÙØ±Ù…Øª Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® Ø¨Ø± Ø§Ø³Ø§Ø³ verbosity_level
            formatted_code_output = f"**Ù¾Ø§Ø³Ø® Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ (verbosity: {code_response_obj.verbosity}):**\n```\n{code_response_obj.code_output}\n```"
            
            return ChatResponse(
                session_id=session_id,
                response=formatted_code_output,
                history=chat_sessions.get(session_id, [])
            )
        except HTTPException as e:
            return ChatResponse(
                session_id=session_id,
                response=f"Ù…ØªØ§Ø³ÙÙ…ØŒ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯: {e.detail}",
                history=chat_sessions.get(session_id, [])
            )
        except Exception as e:
            return ChatResponse(
                session_id=session_id,
                response=f"Ù…ØªØ§Ø³ÙÙ…ØŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø¯ Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯: {e}",
                history=chat_sessions.get(session_id, [])
            )

    # --- Ù…Ù†Ø·Ù‚ Ú†Øª Ø¹Ø§Ø¯ÛŒ (Ø§Ú¯Ø± Ù‡ÛŒÚ† ÛŒÚ© Ø§Ø² Ø¯Ø³ØªÙˆØ±Ø§Øª Ø®Ø§Øµ Ø¨Ø§Ù„Ø§ Ù†Ø¨Ø§Ø´Ø¯) ---
    if session_id not in chat_sessions:
        chat_sessions[session_id] = []
        print(f"Ø¬Ù„Ø³Ù‡ Ú†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ session_id: {session_id} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.")

    current_history = chat_sessions[session_id]

    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡
    current_history.append({"role": "user", "parts": [{"text": user_message}]})

    payload = {
        "contents": current_history,
        "systemInstruction": {
            "parts": [{"text": chat_system_instruction_text}]
        }
    }

    try:
        gemini_response_text = await call_gemini_api(CHAT_MODEL_NAME, payload)
        
        current_history.append({"role": "model", "parts": [{"text": gemini_response_text}]})

        return ChatResponse(
            session_id=session_id,
            response=gemini_response_text,
            history=current_history
        )

    except HTTPException as e:
        raise e
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± /chat/gen Ø¨Ø±Ø§ÛŒ session_id {session_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú†Øª: {e}")

# --- 7. Code Endpoint (/code/gen) ---
@app.post("/code/gen", response_model=CodeResponse)
async def generate_code_response(request: CodeRequest):
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø§Ø² Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø¢Ù† Ø¨Ù‡ Ù…Ø¯Ù„ Gemini 1.5 Pro.
    Ø§ÛŒÙ† Ù…Ø¯Ù„ ÙÙ‚Ø· Ú©Ø¯ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ Ú†Øª Ø¹Ø§Ø¯ÛŒ Ù†ÛŒØ³Øª.
    """
    user_prompt = request.prompt
    verbosity_level = request.verbosity # Ø¯Ø±ÛŒØ§ÙØª Ø³Ø·Ø­ verbosity

    # Ø¯Ø±ÛŒØ§ÙØª system instruction Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø·Ø­ verbosity
    dynamic_code_system_instruction = get_code_system_instruction(verbosity_level)

    payload = {
        "contents": [
            {"role": "user", "parts": [{"text": user_prompt}]}
        ],
        "generationConfig": {
            "responseMimeType": "text/plain"
        },
        "systemInstruction": {
            "parts": [{"text": dynamic_code_system_instruction}] # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² system instruction Ù¾ÙˆÛŒØ§
        }
    }

    try:
        gemini_response_text = await call_gemini_api(CODE_MODEL_NAME, payload)

        return CodeResponse(
            prompt=user_prompt,
            code_output=gemini_response_text,
            verbosity=verbosity_level # Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø³Ø·Ø­ verbosity Ø¯Ø± Ù¾Ø§Ø³Ø®
        )

    except HTTPException as e:
        raise e
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± /code/gen Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª '{user_prompt}': {e}")
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø¯: {e}")


# --- Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ FastAPI ---
# Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ØŒ Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ Ø®ÙˆØ¯ (Ø¯Ø± Ù¾ÙˆØ´Ù‡ Ø­Ø§ÙˆÛŒ main.py Ùˆ .env) Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:
# uvicorn main:app --reload --host 0.0.0.0 --port 8000
# Ø³Ù¾Ø³ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø¢Ø¯Ø±Ø³ http://localhost:8000/docs Ø¨Ù‡ Ù…Ø³ØªÙ†Ø¯Ø§Øª API Ø¯Ø³ØªØ±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒØ¯.
